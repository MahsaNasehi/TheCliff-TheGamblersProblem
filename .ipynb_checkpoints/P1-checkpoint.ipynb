{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSwe_3qWNM_F"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "probability_win = 0.55\n",
    "DISCOUNT_FACTOR = 1\n",
    "reward_table = np.zeros(101)\n",
    "reward_table[100] = 1\n",
    "\n",
    "class StrategyUpdater:\n",
    "    def __init__(self):\n",
    "        self.value_states = np.zeros(101)\n",
    "        self.optimal_strategy = np.zeros(100, dtype=np.int)\n",
    "\n",
    "    def calculate_value(self, position, bet, value_states):\n",
    "        win_outcome = probability_win * (reward_table[position + bet] + DISCOUNT_FACTOR * value_states[position + bet])\n",
    "        lose_outcome = (1 - probability_win) * (reward_table[position - bet] + DISCOUNT_FACTOR * value_states[position - bet])\n",
    "        return win_outcome + lose_outcome\n",
    "\n",
    "    def evaluate_strategy(self, tolerance=1e-14):\n",
    "        while True:\n",
    "            # TODO: Evaluate state values for the current strategy until convergence\n",
    "            # Convergence: The difference in state values between iterations is less than tolerance\n",
    "            delta = 0\n",
    "            new_value_states = self.value_states.copy()\n",
    "\n",
    "            for position in range(1, 100):\n",
    "                bet = self.optimal_strategy[position]\n",
    "                if bet > 0:\n",
    "                    new_value_states[position] = self.calculate_value(position, bet, self.value_states)\n",
    "\n",
    "                delta = max(delta, abs(new_value_states[position] - self.value_states[position]))\n",
    "\n",
    "            self.value_states = new_value_states\n",
    "\n",
    "            if delta < tolerance:\n",
    "                break\n",
    "\n",
    "        return self.update_strategy()\n",
    "\n",
    "    def evaluate_strategy_with_equations(self):\n",
    "        # TODO: Implement strategy evaluation using a system of linear equations\n",
    "\n",
    "        return self.update_strategy()\n",
    "\n",
    "    def update_strategy(self):\n",
    "        # TODO: Implement the strategy improvement algorithm\n",
    "        policy_changed = False\n",
    "        for position in range(1, 100):\n",
    "            best_bet = 0\n",
    "            best_value = 0\n",
    "            # new_value_states = self.value_states.copy()\n",
    "            \n",
    "            for bet in range(1, min(position, 100 - position) + 1):\n",
    "                value = self.calculate_value(position, bet, self.value_states)\n",
    "                if value > best_value:\n",
    "                    best_value = value\n",
    "                    best_bet = bet\n",
    "            if self.optimal_strategy[position] != best_bet:\n",
    "                policy_changed = True\n",
    "            self.optimal_strategy[position] = best_bet\n",
    "            if policy_changed:\n",
    "                return self.evaluate_strategy()\n",
    "        return self.value_states, self.optimal_strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztr-Fsz9NQUo"
   },
   "outputs": [],
   "source": [
    "su = StrategyUpdater()\n",
    "value_estimates, final_strategy = su.evaluate_strategy()\n",
    "# TODO: perform this once by solving equations too\n",
    "print(value_estimates)\n",
    "print(final_strategy)\n",
    "\n",
    "# Plotting the value estimates\n",
    "plt.plot(range(100), value_estimates[:100])\n",
    "plt.xlabel('Capital')\n",
    "plt.ylabel('Value Estimates')\n",
    "plt.title('Value Estimates vs. Capital')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the final policy\n",
    "plt.bar(range(100), final_strategy, align='center', alpha=0.5)\n",
    "for idx in range(100):\n",
    "    plt.text(idx - 0.75, final_strategy[idx] + 0.01, str(round(value_estimates[idx], 2)), fontsize=6)\n",
    "plt.xlabel('Capital')\n",
    "plt.xticks(np.arange(0, 101, 5))\n",
    "plt.ylabel('Final Policy (Stake)')\n",
    "plt.title('Final Policy vs. Capital')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zpQsrr3NV06"
   },
   "outputs": [],
   "source": [
    "# Implementing value iteration and strategy improvement algorithms\n",
    "probability_win = 0.55\n",
    "DISCOUNT_FACTOR = 1\n",
    "reward_table = np.zeros(101)\n",
    "reward_table[100] = 1\n",
    "\n",
    "class ValueCalculator:\n",
    "    def __init__(self):\n",
    "        self.value_states = np.zeros(101, dtype=np.float64)\n",
    "        self.optimal_strategy = np.zeros(100, dtype=np.float64)\n",
    "\n",
    "    def calculate_value(self, position, bet, value_states):\n",
    "        win_outcome = probability_win * (reward_table[position + bet] + DISCOUNT_FACTOR * value_states[position + bet])\n",
    "        lose_outcome = (1 - probability_win) * (reward_table[position - bet] + DISCOUNT_FACTOR * value_states[position - bet])\n",
    "        return win_outcome + lose_outcome\n",
    "\n",
    "    def perform_value_iteration(self, tolerance=1e-50):\n",
    "        # TODO: Implement the value iteration algorithm\n",
    "        while True:\n",
    "            delta = 0\n",
    "            new_value_states = self.value_states.copy()\n",
    "\n",
    "            for position in range(1, 100):  # Skip terminal states\n",
    "                best_value = 0\n",
    "\n",
    "                # Iterate over all valid bets\n",
    "                for bet in range(1, min(position, 100 - position) + 1):\n",
    "                    value = self.calculate_value(position, bet, self.value_states)\n",
    "                    best_value = max(best_value, value)\n",
    "\n",
    "                new_value_states[position] = best_value\n",
    "                delta = max(delta, abs(self.value_states[position] - best_value))\n",
    "\n",
    "            self.value_states = new_value_states\n",
    "\n",
    "            # Check for convergence\n",
    "            if delta < tolerance:\n",
    "                break\n",
    "        return self.perform_strategy_update()\n",
    "\n",
    "    def perform_strategy_update(self):\n",
    "        # TODO: Implement the strategy improvement algorithm\n",
    "        for position in range(1, 100):\n",
    "            best_bet = 0\n",
    "            best_value = 0\n",
    "\n",
    "            # Iterate over all valid bets\n",
    "            for bet in range(1, min(position, 100 - position) + 1):\n",
    "                value = self.calculate_value(position, bet, self.value_states)\n",
    "                if value > best_value:\n",
    "                    best_value = value\n",
    "                    best_bet = bet\n",
    "\n",
    "            self.optimal_strategy[position] = best_bet\n",
    "        return self.value_states, self.optimal_strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iumgm01jNXhD"
   },
   "outputs": [],
   "source": [
    "# Initialize and run value iteration\n",
    "vc = ValueCalculator()\n",
    "value_estimates, final_strategy = vc.perform_value_iteration()\n",
    "print(value_estimates)\n",
    "print(final_strategy)\n",
    "\n",
    "# Plotting the value estimates\n",
    "plt.plot(range(100), value_estimates[:100])\n",
    "plt.xlabel('Capital')\n",
    "plt.ylabel('Value Estimates')\n",
    "plt.title('Value Estimates vs. Capital')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the final policy\n",
    "plt.bar(range(100), final_strategy, align='center', alpha=0.5)\n",
    "for idx in range(100):\n",
    "    plt.text(idx - 0.75, final_strategy[idx] + 0.01, str(round(value_estimates[idx], 2)), fontsize=6)\n",
    "plt.xlabel('Capital')\n",
    "plt.xticks(np.arange(0, 101, 5))\n",
    "plt.ylabel('Final Policy (Stake)')\n",
    "plt.title('Final Policy vs. Capital')\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
